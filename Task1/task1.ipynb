{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b755f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkDissectionAnalyzer:\n",
    "    def __init__(self):\n",
    "        imagenet_csv_path = './results/resnet18_25_07_12_21_16/descriptions.csv'\n",
    "        places365_csv_path = './results/resnet18_places_25_07_12_21_25/descriptions.csv'\n",
    "        self.imagenet_df = pd.read_csv(imagenet_csv_path)\n",
    "        self.places365_df = pd.read_csv(places365_csv_path)\n",
    "        \n",
    "        # Clean column names (remove whitespace)\n",
    "        self.imagenet_df.columns = self.imagenet_df.columns.str.strip()\n",
    "        self.places365_df.columns = self.places365_df.columns.str.strip()\n",
    "        \n",
    "        print(\"Data loaded successfully!\")\n",
    "        print(f\"ImageNet model data shape: {self.imagenet_df.shape}\")\n",
    "        print(f\"Places365 model data shape: {self.places365_df.shape}\")\n",
    "        \n",
    "    def explore_data_structure(self):\n",
    "        \"\"\"Explore the structure of the loaded data\"\"\"\n",
    "        print(\"\\n=== DATA STRUCTURE EXPLORATION ===\")\n",
    "        print(\"\\nImageNet CSV columns:\")\n",
    "        print(self.imagenet_df.columns.tolist())\n",
    "        print(\"\\nPlaces365 CSV columns:\")\n",
    "        print(self.places365_df.columns.tolist())\n",
    "        \n",
    "        print(\"\\nImageNet CSV sample:\")\n",
    "        print(self.imagenet_df.head())\n",
    "        print(\"\\nPlaces365 CSV sample:\")\n",
    "        print(self.places365_df.head())\n",
    "        \n",
    "    def analyze_concept_distribution(self):\n",
    "        \"\"\"Analyze which concepts are learned by most neurons\"\"\"\n",
    "        print(\"\\n=== CONCEPT DISTRIBUTION ANALYSIS ===\")\n",
    "        \n",
    "        # Assuming there's a column for concepts/labels - adjust column name as needed\n",
    "        concept_cols = [col for col in self.imagenet_df.columns if 'concept' in col.lower() or 'label' in col.lower()]\n",
    "        \n",
    "        if not concept_cols:\n",
    "            # If no obvious concept column, look for the main prediction/class column\n",
    "            print(\"Looking for concept/class columns...\")\n",
    "            print(\"Available columns:\", self.imagenet_df.columns.tolist())\n",
    "            \n",
    "            # Try to find the most likely concept column\n",
    "            potential_cols = [col for col in self.imagenet_df.columns \n",
    "                             if any(keyword in col.lower() for keyword in ['class', 'prediction', 'top', 'best'])]\n",
    "            \n",
    "            if potential_cols:\n",
    "                concept_col = potential_cols[0]\n",
    "                print(f\"Using column: {concept_col}\")\n",
    "            else:\n",
    "                # Use the last non-numeric column as concept column\n",
    "                concept_col = self.imagenet_df.select_dtypes(include=['object']).columns[-1]\n",
    "                print(f\"Using last text column: {concept_col}\")\n",
    "        else:\n",
    "            concept_col = concept_cols[0]\n",
    "            print(f\"Using concept column: {concept_col}\")\n",
    "        \n",
    "        # Count concepts for both models\n",
    "        imagenet_concepts = self.imagenet_df[concept_col].value_counts()\n",
    "        places365_concepts = self.places365_df[concept_col].value_counts()\n",
    "        \n",
    "        print(f\"\\nTop 10 concepts in ImageNet model:\")\n",
    "        print(imagenet_concepts.head(10))\n",
    "        \n",
    "        print(f\"\\nTop 10 concepts in Places365 model:\")\n",
    "        print(places365_concepts.head(10))\n",
    "        \n",
    "        return imagenet_concepts, places365_concepts, concept_col\n",
    "    \n",
    "    def compare_models(self, imagenet_concepts, places365_concepts):\n",
    "        \"\"\"Compare concepts learned by both models\"\"\"\n",
    "        print(\"\\n=== MODEL COMPARISON ===\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"Total unique concepts in ImageNet model: {len(imagenet_concepts)}\")\n",
    "        print(f\"Total unique concepts in Places365 model: {len(places365_concepts)}\")\n",
    "        \n",
    "        # Find common and unique concepts\n",
    "        imagenet_set = set(imagenet_concepts.index)\n",
    "        places365_set = set(places365_concepts.index)\n",
    "        \n",
    "        common_concepts = imagenet_set.intersection(places365_set)\n",
    "        imagenet_only = imagenet_set - places365_set\n",
    "        places365_only = places365_set - imagenet_set\n",
    "        \n",
    "        print(f\"Common concepts between models: {len(common_concepts)}\")\n",
    "        print(f\"Concepts only in ImageNet model: {len(imagenet_only)}\")\n",
    "        print(f\"Concepts only in Places365 model: {len(places365_only)}\")\n",
    "        \n",
    "        # Show some examples\n",
    "        print(f\"\\nTop 10 common concepts:\")\n",
    "        common_counts = [(concept, imagenet_concepts[concept], places365_concepts[concept]) \n",
    "                        for concept in common_concepts]\n",
    "        common_counts.sort(key=lambda x: x[1] + x[2], reverse=True)\n",
    "        for concept, img_count, places_count in common_counts[:10]:\n",
    "            print(f\"  {concept}: ImageNet={img_count}, Places365={places_count}\")\n",
    "        \n",
    "        return common_concepts, imagenet_only, places365_only\n",
    "    \n",
    "    def analyze_layers(self):\n",
    "        \"\"\"Analyze neuron distribution across layers\"\"\"\n",
    "        print(\"\\n=== LAYER ANALYSIS ===\")\n",
    "        \n",
    "        # Look for layer information\n",
    "        layer_cols = [col for col in self.imagenet_df.columns if 'layer' in col.lower()]\n",
    "        \n",
    "        if layer_cols:\n",
    "            layer_col = layer_cols[0]\n",
    "            print(f\"Using layer column: {layer_col}\")\n",
    "            \n",
    "            # Count neurons per layer\n",
    "            imagenet_layers = self.imagenet_df[layer_col].value_counts().sort_index()\n",
    "            places365_layers = self.places365_df[layer_col].value_counts().sort_index()\n",
    "            \n",
    "            print(f\"\\nNeurons per layer - ImageNet model:\")\n",
    "            print(imagenet_layers)\n",
    "            \n",
    "            print(f\"\\nNeurons per layer - Places365 model:\")\n",
    "            print(places365_layers)\n",
    "            \n",
    "            return imagenet_layers, places365_layers, layer_col\n",
    "        else:\n",
    "            print(\"No layer column found in the data\")\n",
    "            return None, None, None\n",
    "    \n",
    "    def create_visualizations(self, imagenet_concepts, places365_concepts, concept_col, \n",
    "                            imagenet_layers=None, places365_layers=None, layer_col=None):\n",
    "        \"\"\"Create visualizations for the analysis\"\"\"\n",
    "        print(\"\\n=== CREATING VISUALIZATIONS ===\")\n",
    "        \n",
    "        # Set up the plotting style\n",
    "        plt.style.use('default')\n",
    "        sns.set_palette(\"husl\")\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        \n",
    "        # 1. Top concepts comparison\n",
    "        ax1 = plt.subplot(2, 3, 1)\n",
    "        top_imagenet = imagenet_concepts.head(15)\n",
    "        top_places365 = places365_concepts.head(15)\n",
    "        \n",
    "        x = np.arange(len(top_imagenet))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar(x - width/2, top_imagenet.values, width, label='ImageNet', alpha=0.8)\n",
    "        ax1.bar(x + width/2, top_places365.values[:len(top_imagenet)], width, label='Places365', alpha=0.8)\n",
    "        \n",
    "        ax1.set_xlabel('Concepts')\n",
    "        ax1.set_ylabel('Number of Neurons')\n",
    "        ax1.set_title('Top 15 Concepts: ImageNet vs Places365')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(top_imagenet.index, rotation=45, ha='right')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Concept distribution histogram\n",
    "        ax2 = plt.subplot(2, 3, 2)\n",
    "        bins = np.logspace(0, np.log10(max(imagenet_concepts.max(), places365_concepts.max())), 20)\n",
    "        ax2.hist(imagenet_concepts.values, bins=bins, alpha=0.7, label='ImageNet', density=True)\n",
    "        ax2.hist(places365_concepts.values, bins=bins, alpha=0.7, label='Places365', density=True)\n",
    "        ax2.set_xlabel('Number of Neurons per Concept')\n",
    "        ax2.set_ylabel('Density')\n",
    "        ax2.set_title('Distribution of Neurons per Concept')\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Layer analysis (if available)\n",
    "        if imagenet_layers is not None and places365_layers is not None:\n",
    "            ax3 = plt.subplot(2, 3, 3)\n",
    "            layers = sorted(set(imagenet_layers.index) | set(places365_layers.index))\n",
    "            imagenet_vals = [imagenet_layers.get(layer, 0) for layer in layers]\n",
    "            places365_vals = [places365_layers.get(layer, 0) for layer in layers]\n",
    "            \n",
    "            x = np.arange(len(layers))\n",
    "            ax3.bar(x - width/2, imagenet_vals, width, label='ImageNet', alpha=0.8)\n",
    "            ax3.bar(x + width/2, places365_vals, width, label='Places365', alpha=0.8)\n",
    "            ax3.set_xlabel('Layer')\n",
    "            ax3.set_ylabel('Number of Neurons')\n",
    "            ax3.set_title('Neurons per Layer')\n",
    "            ax3.set_xticks(x)\n",
    "            ax3.set_xticklabels(layers, rotation=45)\n",
    "            ax3.legend()\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Unique vs Common concepts\n",
    "        ax4 = plt.subplot(2, 3, 4)\n",
    "        imagenet_set = set(imagenet_concepts.index)\n",
    "        places365_set = set(places365_concepts.index)\n",
    "        common = len(imagenet_set.intersection(places365_set))\n",
    "        imagenet_only = len(imagenet_set - places365_set)\n",
    "        places365_only = len(places365_set - imagenet_set)\n",
    "        \n",
    "        categories = ['Common', 'ImageNet Only', 'Places365 Only']\n",
    "        values = [common, imagenet_only, places365_only]\n",
    "        colors = ['green', 'blue', 'red']\n",
    "        \n",
    "        wedges, texts, autotexts = ax4.pie(values, labels=categories, autopct='%1.1f%%', \n",
    "                                          colors=colors, startangle=90)\n",
    "        ax4.set_title('Concept Distribution Comparison')\n",
    "        \n",
    "        # 5. Cumulative distribution\n",
    "        ax5 = plt.subplot(2, 3, 5)\n",
    "        imagenet_sorted = np.sort(imagenet_concepts.values)[::-1]\n",
    "        places365_sorted = np.sort(places365_concepts.values)[::-1]\n",
    "        \n",
    "        imagenet_cumsum = np.cumsum(imagenet_sorted) / np.sum(imagenet_sorted)\n",
    "        places365_cumsum = np.cumsum(places365_sorted) / np.sum(places365_sorted)\n",
    "        \n",
    "        ax5.plot(range(len(imagenet_cumsum)), imagenet_cumsum, label='ImageNet', linewidth=2)\n",
    "        ax5.plot(range(len(places365_cumsum)), places365_cumsum, label='Places365', linewidth=2)\n",
    "        ax5.set_xlabel('Concepts (ranked by neuron count)')\n",
    "        ax5.set_ylabel('Cumulative Proportion of Neurons')\n",
    "        ax5.set_title('Cumulative Distribution of Neurons')\n",
    "        ax5.legend()\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Scatter plot comparison\n",
    "        ax6 = plt.subplot(2, 3, 6)\n",
    "        common_concepts = imagenet_set.intersection(places365_set)\n",
    "        if common_concepts:\n",
    "            imagenet_vals = [imagenet_concepts[concept] for concept in common_concepts]\n",
    "            places365_vals = [places365_concepts[concept] for concept in common_concepts]\n",
    "            \n",
    "            ax6.scatter(imagenet_vals, places365_vals, alpha=0.6, s=50)\n",
    "            ax6.set_xlabel('ImageNet Neurons')\n",
    "            ax6.set_ylabel('Places365 Neurons')\n",
    "            ax6.set_title('Common Concepts: Neuron Count Comparison')\n",
    "            ax6.plot([0, max(imagenet_vals)], [0, max(imagenet_vals)], 'r--', alpha=0.5)\n",
    "            ax6.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('network_dissection_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Create summary statistics\n",
    "        self.print_summary_statistics(imagenet_concepts, places365_concepts)\n",
    "    \n",
    "    def print_summary_statistics(self, imagenet_concepts, places365_concepts):\n",
    "        \"\"\"Print comprehensive summary statistics\"\"\"\n",
    "        print(\"\\n=== SUMMARY STATISTICS ===\")\n",
    "        \n",
    "        print(f\"ImageNet Model:\")\n",
    "        print(f\"  Total neurons analyzed: {imagenet_concepts.sum()}\")\n",
    "        print(f\"  Unique concepts: {len(imagenet_concepts)}\")\n",
    "        print(f\"  Mean neurons per concept: {imagenet_concepts.mean():.2f}\")\n",
    "        print(f\"  Median neurons per concept: {imagenet_concepts.median():.2f}\")\n",
    "        print(f\"  Max neurons for single concept: {imagenet_concepts.max()}\")\n",
    "        \n",
    "        print(f\"\\nPlaces365 Model:\")\n",
    "        print(f\"  Total neurons analyzed: {places365_concepts.sum()}\")\n",
    "        print(f\"  Unique concepts: {len(places365_concepts)}\")\n",
    "        print(f\"  Mean neurons per concept: {places365_concepts.mean():.2f}\")\n",
    "        print(f\"  Median neurons per concept: {places365_concepts.median():.2f}\")\n",
    "        print(f\"  Max neurons for single concept: {places365_concepts.max()}\")\n",
    "        \n",
    "        # Diversity metrics\n",
    "        imagenet_entropy = -np.sum((imagenet_concepts / imagenet_concepts.sum()) * \n",
    "                                  np.log(imagenet_concepts / imagenet_concepts.sum()))\n",
    "        places365_entropy = -np.sum((places365_concepts / places365_concepts.sum()) * \n",
    "                                   np.log(places365_concepts / places365_concepts.sum()))\n",
    "        \n",
    "        print(f\"\\nDiversity Metrics:\")\n",
    "        print(f\"  ImageNet entropy: {imagenet_entropy:.3f}\")\n",
    "        print(f\"  Places365 entropy: {places365_entropy:.3f}\")\n",
    "        print(f\"  Higher entropy indicates more diverse concept learning\")\n",
    "    \n",
    "    def generate_insights(self, imagenet_concepts, places365_concepts, common_concepts, \n",
    "                         imagenet_only, places365_only):\n",
    "        \"\"\"Generate insights and findings\"\"\"\n",
    "        print(\"\\n=== KEY INSIGHTS AND FINDINGS ===\")\n",
    "        \n",
    "        # 1. Specialization analysis\n",
    "        print(\"1. Model Specialization:\")\n",
    "        if len(places365_only) > len(imagenet_only):\n",
    "            print(\"   - Places365 model shows more specialized concepts\")\n",
    "        else:\n",
    "            print(\"   - ImageNet model shows more specialized concepts\")\n",
    "        \n",
    "        # 2. Concept overlap\n",
    "        overlap_ratio = len(common_concepts) / len(set(imagenet_concepts.index) | set(places365_concepts.index))\n",
    "        print(f\"   - Concept overlap ratio: {overlap_ratio:.3f}\")\n",
    "        \n",
    "        # 3. Distribution analysis\n",
    "        imagenet_top10_ratio = imagenet_concepts.head(10).sum() / imagenet_concepts.sum()\n",
    "        places365_top10_ratio = places365_concepts.head(10).sum() / places365_concepts.sum()\n",
    "        \n",
    "        print(f\"2. Concentration Analysis:\")\n",
    "        print(f\"   - ImageNet: Top 10 concepts account for {imagenet_top10_ratio:.1%} of neurons\")\n",
    "        print(f\"   - Places365: Top 10 concepts account for {places365_top10_ratio:.1%} of neurons\")\n",
    "        \n",
    "        # 4. Unique concept examples\n",
    "        print(f\"3. Dataset-Specific Learning:\")\n",
    "        print(f\"   - ImageNet-only concepts (examples): {list(imagenet_only)[:5]}\")\n",
    "        print(f\"   - Places365-only concepts (examples): {list(places365_only)[:5]}\")\n",
    "        \n",
    "        # 5. Common high-activation concepts\n",
    "        if common_concepts:\n",
    "            common_high = [(concept, imagenet_concepts[concept] + places365_concepts[concept]) \n",
    "                          for concept in common_concepts]\n",
    "            common_high.sort(key=lambda x: x[1], reverse=True)\n",
    "            print(f\"4. Most Important Common Concepts:\")\n",
    "            for concept, total_neurons in common_high[:5]:\n",
    "                print(f\"   - {concept}: {total_neurons} total neurons\")\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "        print(\"Starting Network Dissection Analysis...\")\n",
    "        \n",
    "        # Step 1: Explore data structure\n",
    "        self.explore_data_structure()\n",
    "        \n",
    "        # Step 2: Analyze concept distribution\n",
    "        imagenet_concepts, places365_concepts, concept_col = self.analyze_concept_distribution()\n",
    "        \n",
    "        # Step 3: Compare models\n",
    "        common_concepts, imagenet_only, places365_only = self.compare_models(imagenet_concepts, places365_concepts)\n",
    "        \n",
    "        # Step 4: Analyze layers\n",
    "        imagenet_layers, places365_layers, layer_col = self.analyze_layers()\n",
    "        \n",
    "        # Step 5: Create visualizations\n",
    "        self.create_visualizations(imagenet_concepts, places365_concepts, concept_col,\n",
    "                                 imagenet_layers, places365_layers, layer_col)\n",
    "        \n",
    "        # Step 6: Generate insights\n",
    "        self.generate_insights(imagenet_concepts, places365_concepts, common_concepts,\n",
    "                              imagenet_only, places365_only)\n",
    "        \n",
    "        print(\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "        print(\"Visualization saved as 'network_dissection_analysis.png'\")\n",
    "        print(\"Use the insights above for your report!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Create analyzer instance\n",
    "    analyzer = NetworkDissectionAnalyzer()\n",
    "    \n",
    "    # Run complete analysis\n",
    "    analyzer.run_complete_analysis()\n",
    "    \n",
    "    # You can also run individual analyses:\n",
    "    # analyzer.explore_data_structure()\n",
    "    # imagenet_concepts, places365_concepts, concept_col = analyzer.analyze_concept_distribution()\n",
    "    # common_concepts, imagenet_only, places365_only = analyzer.compare_models(imagenet_concepts, places365_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d6486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
