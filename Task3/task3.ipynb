{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bcb929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries, slic, quickshift, felzenszwalb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e775576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_slic_segmentation(image):\n",
    "    \"\"\"Optimized SLIC segmentation for better IoU with reasonable speed\"\"\"\n",
    "    return slic(image, n_segments=100, compactness=15, sigma=1, start_label=1, max_num_iter=15)\n",
    "\n",
    "def quick_felzenszwalb_segmentation(image):\n",
    "    \"\"\"Faster Felzenszwalb for complex scenes\"\"\"\n",
    "    return felzenszwalb(image, scale=150, sigma=0.8, min_size=30)\n",
    "\n",
    "class OptimizedLIMEExplainer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize LIME explainer with ResNet50 model\"\"\"\n",
    "        # Load pre-trained ResNet50 model\n",
    "        self.model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Define image transformations\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Initialize LIME explainer\n",
    "        self.explainer = lime_image.LimeImageExplainer()\n",
    "        \n",
    "        # Load ImageNet class labels\n",
    "        self.load_imagenet_labels()\n",
    "        \n",
    "        # Image URLs from the assignment\n",
    "        self.image_urls = {\n",
    "            'West_Highland_white_terrier': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n02098286_West_Highland_white_terrier.JPEG',\n",
    "            'American_coot': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n02018207_American_coot.JPEG',\n",
    "            'racer': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n04037443_racer.JPEG',\n",
    "            'flamingo': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n02007558_flamingo.JPEG',\n",
    "            'kite': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n01608432_kite.JPEG',\n",
    "            'goldfish': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n01443537_goldfish.JPEG',\n",
    "            'tiger_shark': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n01491361_tiger_shark.JPEG',\n",
    "            'vulture': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n01616318_vulture.JPEG',\n",
    "            'common_iguana': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n01677366_common_iguana.JPEG',\n",
    "            'orange': 'https://github.com/EliSchwartz/imagenet-sample-images/raw/master/n07747607_orange.JPEG'\n",
    "        }\n",
    "    \n",
    "    def load_imagenet_labels(self):\n",
    "        \"\"\"Load ImageNet class labels\"\"\"\n",
    "        try:\n",
    "            url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "            response = requests.get(url)\n",
    "            self.class_labels = response.text.strip().split('\\n')\n",
    "        except:\n",
    "            self.class_labels = [f\"class_{i}\" for i in range(1000)]\n",
    "    \n",
    "    def load_image(self, url):\n",
    "        \"\"\"Load image from URL\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image from {url}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def classifier_fn(self, images):\n",
    "        # Use smaller batch size for better memory management and speed\n",
    "        batch_size = min(32, len(images))\n",
    "        all_probabilities = []\n",
    "        \n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch_images = images[i:i + batch_size]\n",
    "            batch = []\n",
    "            \n",
    "            for img in batch_images:\n",
    "                pil_img = Image.fromarray(img.astype('uint8'))\n",
    "                tensor_img = self.transform(pil_img).unsqueeze(0)\n",
    "                batch.append(tensor_img)\n",
    "            \n",
    "            batch_tensor = torch.cat(batch, dim=0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(batch_tensor)\n",
    "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                all_probabilities.append(probabilities.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(all_probabilities)\n",
    "    \n",
    "    def get_prediction(self, image):\n",
    "        \"\"\"Get model prediction for an image\"\"\"\n",
    "        input_tensor = self.transform(image).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "    \n",
    "    def create_optimized_parameters(self):        \n",
    "        key_names = [\n",
    "            'West_Highland_white_terrier',\n",
    "            'American_coot', \n",
    "            'racer',\n",
    "            'flamingo',\n",
    "            'kite',\n",
    "            'goldfish',\n",
    "            'tiger_shark',\n",
    "            'vulture',\n",
    "            'common_iguana',\n",
    "            'orange'\n",
    "        ]\n",
    "        \n",
    "        all_params = {}\n",
    "        \n",
    "        for name in key_names:\n",
    "            # Base parameters optimized for speed-accuracy balance\n",
    "            base_params = {\n",
    "                \"labels\": (1,),\n",
    "                \"hide_color\": 0,\n",
    "                \"top_labels\": 1,\n",
    "                \"num_features\": 10,      # Balanced - not too high\n",
    "                \"num_samples\": 300,      # Balanced for speed-accuracy\n",
    "                \"batch_size\": 32,        # Smaller for better speed\n",
    "                \"segmentation_fn\": optimized_slic_segmentation,\n",
    "                \"distance_metric\": \"cosine\",\n",
    "                \"model_regressor\": None,\n",
    "                \"random_seed\": 42\n",
    "            }\n",
    "            \n",
    "            # Targeted optimization for problem images\n",
    "            if name in ['goldfish', 'orange']:\n",
    "                # Simple objects - can use fewer samples\n",
    "                base_params.update({\n",
    "                    \"num_features\": 8,\n",
    "                    \"num_samples\": 250,\n",
    "                    \"segmentation_fn\": optimized_slic_segmentation\n",
    "                })\n",
    "            elif name in ['West_Highland_white_terrier', 'American_coot', 'flamingo']:\n",
    "                # Clear subjects - moderate parameters\n",
    "                base_params.update({\n",
    "                    \"num_features\": 10,\n",
    "                    \"num_samples\": 300,\n",
    "                    \"segmentation_fn\": optimized_slic_segmentation\n",
    "                })\n",
    "            elif name in ['vulture', 'tiger_shark', 'common_iguana']:\n",
    "                # Problem images - need better segmentation and more features\n",
    "                base_params.update({\n",
    "                    \"num_features\": 12,       # More features for complex scenes\n",
    "                    \"num_samples\": 350,       # More samples for accuracy\n",
    "                    \"segmentation_fn\": quick_felzenszwalb_segmentation,  # Better segmentation\n",
    "                    \"hide_color\": 0           # Keep color info for these complex images\n",
    "                })\n",
    "            elif name == 'kite':\n",
    "                # Most problematic - special handling\n",
    "                base_params.update({\n",
    "                    \"num_features\": 14,       # Even more features\n",
    "                    \"num_samples\": 400,       # More samples\n",
    "                    \"segmentation_fn\": quick_felzenszwalb_segmentation,\n",
    "                    \"hide_color\": 0,\n",
    "                    \"distance_metric\": \"euclidean\"\n",
    "                })\n",
    "            elif name == 'racer':\n",
    "                # Vehicle - moderate complexity\n",
    "                base_params.update({\n",
    "                    \"num_features\": 11,\n",
    "                    \"num_samples\": 320,\n",
    "                    \"segmentation_fn\": optimized_slic_segmentation\n",
    "                })\n",
    "            \n",
    "            all_params[name] = base_params\n",
    "        \n",
    "        return all_params\n",
    "    \n",
    "    def create_pickle_safe_optimized_parameters(self):\n",
    "        \"\"\"Create optimized parameters without function references for pickle\"\"\"\n",
    "        \n",
    "        key_names = [\n",
    "            'West_Highland_white_terrier',\n",
    "            'American_coot', \n",
    "            'racer',\n",
    "            'flamingo',\n",
    "            'kite',\n",
    "            'goldfish',\n",
    "            'tiger_shark',\n",
    "            'vulture',\n",
    "            'common_iguana',\n",
    "            'orange'\n",
    "        ]\n",
    "        \n",
    "        all_params = {}\n",
    "        \n",
    "        for name in key_names:\n",
    "            # Base parameters - balanced for speed and accuracy\n",
    "            base_params = {\n",
    "                \"labels\": (1,),\n",
    "                \"hide_color\": 0,\n",
    "                \"top_labels\": 1,\n",
    "                \"num_features\": 10,\n",
    "                \"num_samples\": 300,\n",
    "                \"batch_size\": 32,\n",
    "                \"segmentation_fn\": None,  # Use LIME default\n",
    "                \"distance_metric\": \"cosine\",\n",
    "                \"model_regressor\": None,\n",
    "                \"random_seed\": 42\n",
    "            }\n",
    "            \n",
    "            # Targeted optimization\n",
    "            if name in ['goldfish', 'orange']:\n",
    "                # Simple objects\n",
    "                base_params.update({\n",
    "                    \"num_features\": 8,\n",
    "                    \"num_samples\": 250\n",
    "                })\n",
    "            elif name in ['West_Highland_white_terrier', 'American_coot', 'flamingo']:\n",
    "                # Clear subjects\n",
    "                base_params.update({\n",
    "                    \"num_features\": 10,\n",
    "                    \"num_samples\": 300\n",
    "                })\n",
    "            elif name in ['vulture', 'tiger_shark', 'common_iguana']:\n",
    "                # Problem images - targeted improvement\n",
    "                base_params.update({\n",
    "                    \"num_features\": 12,\n",
    "                    \"num_samples\": 350,\n",
    "                    \"hide_color\": 0\n",
    "                })\n",
    "            elif name == 'kite':\n",
    "                # Most problematic\n",
    "                base_params.update({\n",
    "                    \"num_features\": 14,\n",
    "                    \"num_samples\": 400,\n",
    "                    \"hide_color\": 0,\n",
    "                    \"distance_metric\": \"euclidean\"\n",
    "                })\n",
    "            elif name == 'racer':\n",
    "                # Vehicle\n",
    "                base_params.update({\n",
    "                    \"num_features\": 11,\n",
    "                    \"num_samples\": 320\n",
    "                })\n",
    "            \n",
    "            all_params[name] = base_params\n",
    "        \n",
    "        return all_params\n",
    "    \n",
    "    def generate_lime_explanation(self, image, image_name, params):\n",
    "        \"\"\"Generate LIME explanation with timing\"\"\"\n",
    "        import time\n",
    "        \n",
    "        image_np = np.array(image)\n",
    "        predicted_class, confidence = self.get_prediction(image)\n",
    "        predicted_label = self.class_labels[predicted_class]\n",
    "        \n",
    "        print(f\"Analyzing {image_name}:\")\n",
    "        print(f\"Predicted class: {predicted_label} (confidence: {confidence:.3f})\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Generate explanation\n",
    "        explanation = self.explainer.explain_instance(\n",
    "            image_np, \n",
    "            self.classifier_fn,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Explanation generated in {execution_time:.3f} seconds\")\n",
    "        \n",
    "        return explanation, predicted_class, predicted_label, confidence, execution_time\n",
    "    \n",
    "    def visualize_lime_explanation(self, image, explanation, image_name, predicted_class, predicted_label, confidence):\n",
    "        \"\"\"Visualize LIME explanation\"\"\"\n",
    "        # Get image and mask from explanation\n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            predicted_class, \n",
    "            positive_only=True, \n",
    "            num_features=8,  # Show reasonable number of features\n",
    "            hide_rest=False\n",
    "        )\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title(f'Original Image\\n{image_name}', fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # LIME explanation\n",
    "        axes[1].imshow(mark_boundaries(temp / 255.0, mask))\n",
    "        axes[1].set_title(f'LIME Explanation\\n{predicted_label}\\nConf: {confidence:.3f}', fontsize=12)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Important regions only\n",
    "        temp_neg, mask_neg = explanation.get_image_and_mask(\n",
    "            predicted_class, \n",
    "            positive_only=False, \n",
    "            num_features=8,\n",
    "            hide_rest=True\n",
    "        )\n",
    "        axes[2].imshow(mark_boundaries(temp_neg / 255.0, mask_neg))\n",
    "        axes[2].set_title('Important Regions Only', fontsize=12)\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'lime_explanation_{image_name}_optimized.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print feature importance\n",
    "        features = explanation.local_exp[predicted_class]\n",
    "        sorted_features = sorted(features, key=lambda x: abs(x[1]), reverse=True)[:6]\n",
    "        print(f\"Top 6 feature importances: {[(f[0], f'{f[1]:.4f}') for f in sorted_features]}\")\n",
    "        print()\n",
    "        \n",
    "        return temp, mask\n",
    "    \n",
    "    def analyze_all_images_optimized(self):\n",
    "        \"\"\"Analyze all images with optimized parameters\"\"\"\n",
    "        all_params = self.create_optimized_parameters()\n",
    "        \n",
    "        results = {}\n",
    "        total_time = 0\n",
    "                \n",
    "        for image_name, url in self.image_urls.items():\n",
    "            print(f\"Processing {image_name}...\")\n",
    "            \n",
    "            image = self.load_image(url)\n",
    "            if image is None:\n",
    "                print(f\"Failed to load {image_name}, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            params = all_params[image_name].copy()\n",
    "            # Remove parameters that shouldn't be passed to explain_instance\n",
    "            params.pop('labels', None)\n",
    "            params.pop('top_labels', None)\n",
    "            \n",
    "            try:\n",
    "                explanation, predicted_class, predicted_label, confidence, execution_time = self.generate_lime_explanation(\n",
    "                    image, image_name, params\n",
    "                )\n",
    "                \n",
    "                total_time += execution_time\n",
    "                \n",
    "                # Visualize explanation\n",
    "                temp, mask = self.visualize_lime_explanation(\n",
    "                    image, explanation, image_name, predicted_class, predicted_label, confidence\n",
    "                )\n",
    "                \n",
    "                results[image_name] = {\n",
    "                    'explanation': explanation,\n",
    "                    'predicted_class': predicted_class,\n",
    "                    'predicted_label': predicted_label,\n",
    "                    'confidence': confidence,\n",
    "                    'image': image,\n",
    "                    'visualization': (temp, mask),\n",
    "                    'execution_time': execution_time\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        avg_time = total_time / len(results) if results else 0\n",
    "        print(f\"\\nAverage execution time per image: {avg_time:.3f} seconds\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_optimized_parameters_pickle(self, filename=\"lime_parameters_optimized.pkl\"):\n",
    "        \"\"\"Save optimized parameters to pickle file\"\"\"\n",
    "        params = self.create_pickle_safe_optimized_parameters()\n",
    "        \n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(params, f)\n",
    "        \n",
    "        print(f\"Optimized parameters saved to {filename}\")\n",
    "        self.verify_pickle_file(filename)\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def verify_pickle_file(self, filename):\n",
    "        \"\"\"Verify the pickle file format\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                loaded_params = pickle.load(f)\n",
    "            \n",
    "            print(f\"\\nVerification of {filename}:\")\n",
    "            print(f\"Number of entries: {len(loaded_params)}\")\n",
    "            \n",
    "            expected_keys = [\n",
    "                'West_Highland_white_terrier', 'American_coot', 'racer', 'flamingo', 'kite',\n",
    "                'goldfish', 'tiger_shark', 'vulture', 'common_iguana', 'orange'\n",
    "            ]\n",
    "            \n",
    "            missing_keys = [key for key in expected_keys if key not in loaded_params]\n",
    "            extra_keys = [key for key in loaded_params if key not in expected_keys]\n",
    "            \n",
    "            if not missing_keys and not extra_keys:\n",
    "                print(\"✅ All required keys present, no extra keys\")\n",
    "            else:\n",
    "                if missing_keys:\n",
    "                    print(f\"❌ Missing keys: {missing_keys}\")\n",
    "                if extra_keys:\n",
    "                    print(f\"❌ Extra keys: {extra_keys}\")\n",
    "            \n",
    "            # Show parameters for problem images\n",
    "            problem_images = ['vulture', 'tiger_shark', 'kite', 'common_iguana']\n",
    "            print(\"\\nParameters for problem images:\")\n",
    "            for img in problem_images:\n",
    "                if img in loaded_params:\n",
    "                    params = loaded_params[img]\n",
    "                    print(f\"{img}: samples={params.get('num_samples')}, features={params.get('num_features')}\")\n",
    "            \n",
    "            print(\"✅ Optimized pickle file created successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error verifying pickle file: {e}\")\n",
    "    \n",
    "    def submit_to_server(self, pickle_file, token):\n",
    "        \"\"\"Submit pickle file to server\"\"\"\n",
    "        try:\n",
    "            url = \"http://34.122.51.94:9091/lime\"\n",
    "            \n",
    "            with open(pickle_file, \"rb\") as f:\n",
    "                response = requests.post(\n",
    "                    url,\n",
    "                    files={\"file\": f},\n",
    "                    headers={\"token\": token}\n",
    "                )\n",
    "            \n",
    "            print(f\"Submission response status: {response.status_code}\")\n",
    "            \n",
    "            try:\n",
    "                response_json = response.json()\n",
    "                print(f\"Response JSON: {response_json}\")\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    print(\"✅ Submission successful!\")\n",
    "                    if 'avg_iou' in response_json:\n",
    "                        iou = response_json['avg_iou']\n",
    "                        print(f\"Average IoU: {iou:.4f}\")\n",
    "                    if 'avg_time' in response_json:\n",
    "                        time_val = response_json['avg_time']\n",
    "                        print(f\"Average Time: {time_val:.4f} seconds\")\n",
    "                else:\n",
    "                    print(f\"❌ Submission failed with status {response.status_code}\")\n",
    "                    \n",
    "            except Exception as json_error:\n",
    "                print(f\"Could not parse JSON response: {json_error}\")\n",
    "                print(f\"Raw response: {response.text}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during submission: {e}\")\n",
    "\n",
    "def main_optimized():\n",
    "    \"\"\"Main function for optimized LIME analysis\"\"\"\n",
    "    explainer = OptimizedLIMEExplainer()\n",
    "    \n",
    "    # 1. Analyze all images\n",
    "    results = explainer.analyze_all_images_optimized()\n",
    "    \n",
    "    # 2. Create and save parameters\n",
    "    params = explainer.save_optimized_parameters_pickle()\n",
    "    \n",
    "    # 3. Submit to server\n",
    "    token = \"96005201\"  # Replace with your actual token\n",
    "    explainer.submit_to_server(\"lime_parameters_optimized.pkl\", token)\n",
    "    \n",
    "    print(\"\\n=== OPTIMIZED LIME Analysis Summary ===\")\n",
    "    print(f\"Successfully analyzed {len(results)} images\")\n",
    "\n",
    "    return results, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results, params = main_optimized()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
